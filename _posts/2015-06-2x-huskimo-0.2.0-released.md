---
layout: post
shortenedlink: Huskimo 0.2.0 released
title: "Huskimo 0.2.0 released: warehouse your Singular marketing spend data in Redshift"
tags: [huskimo, marketing, spend, redshift]
author: Alex
category: Releases
---

We are pleased to announce Huskimo, an all-new open-source product from the Snowplow team. This initial release of Huskimo is for companies who use [Singular] [singular] to manage their mobile marketing campaigns, and would like to analyze the Singular marketing spend data in Amazon Redshift, alongside their Snowplow event data.

ADD A PICTURE OF A HUSKIMO

Although this is version 0.2.0 of Huskimo, this is the first publicized release, and so we will take some time in this blog post to explain the rationale for Huskimo as an all-new open-source project.

Read on after the jump for:

1. [Why Huskimo?](/blog/2015/06/21/huskimo-0.2.0-released-released#why)
2. [Singular support](/blog/2015/06/21/huskimo-0.2.0-released-released#singular)
3. [Running Huskimo](/blog/2015/06/21/huskimo-0.2.0-released-released#setup)
4. [Loading configuration from DynamoDB](/blog/2015/06/21/huskimo-0.2.0-released-released#dynamodb)
5. [Randomized partition keys for bad streams](/blog/2015/06/21/huskimo-0.2.0-released-released#randomization)
6. [Removal of automatic stream creation](/blog/2015/06/21/huskimo-0.2.0-released-released#automaticStreams)
7. [Improved Elasticsearch index initialization](/blog/2015/06/21/huskimo-0.2.0-released-released#tokenization)
8. [Other changes](/blog/2015/06/21/huskimo-0.2.0-released-released#otherChanges)
9. [Upgrading](/blog/2015/06/21/huskimo-0.2.0-released-released#upgrading)
10. [Getting help](/blog/2015/06/21/huskimo-0.2.0-released-released#help)

<!--more-->

<h2><a name="why">1. Why Huskimo?</a></h2>

At Snowplow we strongly believe that _events_ are the most effective currency for capturing digital activity of any form. To enable this, we provide a variety of language/platform specific [trackers] [trackers], plus growing support for various third-party SaaS platforms via [webhooks] [webhooks].

However, not all third-party SaaS platforms are willing or able to expose their internal stateful data as a stream of immutable events; some of these platforms are the very ones that Snowplow users are _most_ excited about querying in Redshift alongside their Snowplow event data.

To bridge the gap, we are now open sourcing the [Huskimo project] [huskimo]. Huskimo has a simple goal: to make essential datasets currently locked away inside various SaaS platforms available for analysis inside Redshift.

At launch, we are supporting just one SaaS platform: [Singular] [singular], which is a tool for managing marketing spend focused on mobile apps and games companies.

<h2><a name="singular">2. Singular support</a></h2>

Huskimo supports two API resources made available by Singular:

1. xxx
2. xxx

For each resource type, Huskimo will retrieve all records from the Singular API, convert them into a simple TSV file format, and load them into Redshift.

The most complex aspect of Huskimo is dealing with Singular marketing data becoming "golden" - Huskimo's approach to this is covered in the next section.

<h2><a name="singular">3. Marketing data: a primer</a></h2>

Marketing data is notoriously difficult to finalize - it takes days (sometimes weeks) for advertising companies to determine which clicks on ads were real, and which ones were fraudulent. This means that it also takes days or weeks for marketing spend data to be finalized, sometimes referred to as “becoming golden”.

As a result, we can retrieve say Sunday's spend data from Singular on Monday, but we have to be aware that if we fetch Sunday's spend data again on Tuesday, the numbers for Sunday will very likely have changed.

Huskimo gets around this by:

1. Attaching a `when_retrieved` XXX to each row of data retrieved from Singular
2. 

The data that online advertising companies provide to their customers is another example. As a result of this, any join we do in a stream processing job between our ad click and what we paid for that click will only be a first estimate, and subject to refinement using our late arriving data.

<h2><a name="setup">3. Running Huskimo</a></h2>

Running Huskimo consists of three steps:

1. Install Huskimo
2. Write the Hukimo config file
3. Deploy the Redshift tables
4. Schedule Huskimo to run nightly

We'll cover each of these steps briefly in the next section.

<h3>Install Huskimo</h3>

Huskimo is made available as an executable "fatjar" runnable on any Linux system. It is hosted on Bintray, download it like so:

{% highlight bash %}
$ wget http://dl.bintray.com/snowplow/snowplow-generic/huskimo_0.2.0.zip
{% endhighlight %}

Once downloaded, unzip it:

{% highlight bash %}
$ unzip huskimo_0.2.0.zip
{% endhighlight %}

Assuming you have a recent (Java 7 or 8) runtime on your system, running is as simple as:

{% highlight bash %}
$ ./huskimo --version
{% endhighlight %}

<h3>Write the Huskimo config file</h3>

Huskimo is configured using a YAML-format file which looks like this:

{% highlight yaml %}

{% endhighlight %}

Key things to note:

1. You can configure Huskimo to extract from one or more Singular accounts
2. You can configure Huskimo to write the extracted data to one or more Redshift databases

<h3>Deploy the Redshift tables</h3>

Before starting Huskimo you must remember to deploy the two Singular tables into Redshift. You can find the table definitions in the file:

 XXX.sql - 

Make sure to deploy this file against each Redshift database you want to load Singular data into.

<h3>Schedule Huskimo to run nightly</h3>

You are now ready to schedule Huskimo to run nightly. We would typically run Huskimo in the early morning so that the data for yesterday is already available in some form. A cron entry for Huskimo might look something like this:

xxx

<h2><a name="singular">3. Huskimo architecture</a></h2>

The Huskimo architecture is relatively simple: for a given API resource, e.g. campaigns, Huskimo will extract all resources

The Huskimo arcrchtiecture

<h2><a name="help">X-1. Getting help</a></h2>

For more details on this release, please check out the [Huskimo 0.2.0][020-release] on GitHub. 

We will be building a dedicated wiki for Huskimo to explain how to use it; in the meantime, if you have any questions or run into any problems, please [raise an issue][issues] or get in touch with us through [the usual channels][talk-to-us].

<h2><a name="why">X. Huskimo roadmap</a></h2>

We will be adding support for further SaaS platforms to Huskimo on a case-by-case basis. The next release (0.3.0) of Huskimo will extract the major resource types from [Twilio] [twilio], the popular Telephony-as-a-Service provider.

We are also particularly interested in adding support for more marketing channels, such as Google AdWords or Facebook. Having these datasets available in Redshift alongside your event data should be hugely powerful for marketing attribution and return-on-spend analytics.

**If this is something you would be interested in sponsoring, do [get in touch] [sponsorship-contact]!**

[huskimo-img]: /assets/img/blog/2015/06/huskimo.jpg

[huskimo]: https://github.com/snowplow/huskimo
[020-release]: https://github.com/snowplow/huskimo/releases/tag/0.2.0

[singular]: xxx
[twilio]: xxx

[trackers]: xxx
[webhooks]: xxx

[issues]: https://github.com/snowplow/huskimo/issues
[talk-to-us]: https://github.com/snowplow/snowplow/wiki/Talk-to-us

[sponsorship-contact]: mailto:contact@snowplowanalytics.com
