---
layout: post
shortenedlink: Semantic event modeling and entity snapshotting
title: Semantic event modeling and entity snapshotting
tags: [event, analytics, grammar, model, entities]
author: Alex
category: Research
---

At Snowplow we spend a lot of time thinking about how to model events. As businesses re-orient themselves around event streams under the [Unified Log model] [kreps], it becomes ever more important to properly model those event streams. After all: "garbage in" means "garbage out": deriving business value from events is hugely dependent on modeling those events correctly in the first place.

Our focus at Snowplow has been on defining a **semantic model** for events: one that is built around the intrinsic properties found across all events. A semantic model helps to prevent business and technology assumptions from leaking into the event stream. This works to guard against outdated assumptions becoming "fossilized" in the event stream, and helps to make those streams significantly less brittle - and easier to evolve - over time.

We proposed an initial model for Snowplow events in our August 2013 blog post, [Towards universal event analytics - building an event grammar] [snowplow-event-grammar]. We have since discussed this approach with many interested parties, and have been pleased to follow other explorations of the topic, for example CARMEN'S BLOG POST SERIES. I've also made heavy use of this proposed event grammar in my book, [Unified Log Processing] [dean]. The semantic approach seems to have resonated widely.

However, our thinking has evolved from our original event grammar proposal in one important aspect. During the 18 months elapsed since that blog post, we have been exposed to many more event streams defined by many more customers, and we have also had the chance to experiment with aspects of the event grammar through Snowplow's own unstructured events, its custom contexts and more generally with our new [Iglu] [iglu] project. What we have learnt from all this can be summed up like so:

> An event is anything that we can observe occurring at a particular point in time. Each event is recorded as the set of relevant entities as they stood at that point in time

This statement may seem unrelated - perhaps even contradictory - to our original definition of an event grammar with six dedicated "slots" containing: Subject, Verb, Object, Indirect Object, Prepositional Object and Context. In fact, they are closely related and broadly complementary, and understanding the role of entities in events should allow us to derive a "version 2" of our event grammar which is significantly simpler and also more powerful.

In the rest of this blog post, we will XXXXXXXXXXX

CONTENTS SECTION?

<!--more-->

<div class="html">
<h2><a name="emitters">1. Introducing entities</a></h2>
</div>

What is an entity? In event modeling terms, an entity is a thing or object which is somehow _relevant to_ the event that we are observing. For example, in the sentence "I watched Interstellar at my local theatre", myself, the movie and the movie theatre are all entities. We use the word "entity" because the word "object" is too loaded - it has too many connotations from Object-Oriented Programming (OOP), and it also has a separate grammatical meaning in terms of the "subject" of a verb versus the "object" of a verb.

ADD DIAGRAM

Entities are everywhere in software. MySQL tables, backbone.js models, Protocol Buffers, JSONs, Plain Old Java Objects, XML documents, Haskell records - as programmers we spend an inordinate amount of time working with the entities that matter to our systems. It is no coincidence that these entities play a huge role in the events which occur in and around our software too.

There is a lot of confusion around the role of entities within events - even to the extent of one analytics company arguing that entity data is [completely distinct] [keen-entities-vs-events] from event data. In fact nothing could be further from the truth - as we'll soon see, our events consist of almost _nothing but_ entities. But before we look at the event-entity relationship, we need to understand how entities interact with time.

<div class="html">
<h2><a name="entities-and-time">2. Entities and time</a></h2>
</div>

> All objects exist in a moment of time

Amy Tan, The Bonesetter's Daughter

In the real world as in software, entities change over time. If we can view our entities as consisting of properties, we can divide these properties into three approximate buckets:

* **Permanent or static properties** - properties that don't change over the lifetime of the entity. For example, my first language
* **Infrequently changing properties** - properties that change infrequently, for instance my email address
* **Frequently changing properties** - properties that frequently change. For example, my geographical location

The exact taxonomy is not set in stone - for example, a person's height will start as a frequently changing property, become a static property in adulthood, and then switch to an infrequently changing property as she grows older. Nor do these properties necessarily change in particularly directional or meaningful ways over time: my geographical location has patterns in it (such as my daily commute), but there's no overarching trend across all the data.

Let's imagine that Jack is playing a mobile game, and saving his progress as he goes. Jack is an entity, and the mobile game is another entity. Across three distinct save game events, Jack's internal properties change:

ADD DIAGRAM

To put it another way: it was a slightly different Jack who saved his game each time. If we want to analyze and understand these save game events, being able to review the "version of Jack" who enacted each event could be hugely important. How can we do this?

<div class="html">
<h2><a name="on-remembering">3. Time and databases</a></h2>
</div>

> What matters in life is not what happens to you but what you remember and how you remember it

Gabriel Garcí­a Márquez

We are surrounded by software that helps us to model entities in one form or another. Separately, we've learnt that the entities we care about change over time. Presumably all of this entity-modeling software makes it easy to record how our entities are slowly (or rapidly) changing over time? Actually, most of it does not.

Most systems that represent entities - databases, schema languages, serialization protocols and so on - have no concept of time as a dimension. These systems most often simply track the _current_ state of each entity: accordingly as developers we are expected to _update in place_ the existing data when some property changes. If Jack's email address changes, then we must update the existing `email_address` value in his record in the `players` table. In many systems, it is as if Jack's email address was always the new one.

This isn't such a problem for permanent or static properties like Jack's first language - but it's a real pain for properties that change infrequently or frequently, such as his email address or location. Various software approaches have emerged to tackle this problem:

* **Value versioning.** In the HBase database, a cell (a.k.a. a value) is specified by a [`{row, column, version}` tuple] [hbase-versioning]. You can configure HBase to store hundreds of versions of a column. By default the most recent version is returned, but you can also retrieve the value at a specific timestamp or between two timestamps
* **Fact databases.** The [Datomic database] [datomic-rationale] stores "datoms" or facts consisting of an entity, attribute, value and "transaction" (i.e. time). These datoms are immutable facts - they are never updated, but new ones can be appended. You can query the database at a point in time or across a time window
* **Periodic snapshots.** In data warehousing, an ETL process can regularly (e.g. daily) capture the entity data from a transactional database at a moment in time, and store it in fact tables in the data warehouse
* **Log triggers.** A [log or history trigger] [log-trigger] is set up in a database to automatically record all C/U/D (Create, Update, Delete) events on a given table
* **Event sourcing.** Where all changes to application state are stored as an [append-only sequence of immutable events] [event-sourcing]: we stop worrying about state and start worrying about _state transitions_. If we need an entity's current state, then we can calculate it from the relevant event sequence

Each of these approaches to [Change Data Capture] [cdc] has different pros and cons. And more importantly, many companies won't have any Change Data Capture in place. So how do we make sure that we can cross-reference our events against the relevant entities as they existed _at the time of the event_?  

<div class="html">
<h2><a name="entity-snapshotting">4. Entity snapshotting</a></h2>
</div>

Storage is cheap and getting cheaper. Networks are getting faster all the time. If we care about the entities relevant to a given event, why don't we just interrogate their state at the exact moment of the event and record these entities' state as part of our event? To put it another way: let's **snapshot** our entities' state inside of our events, and record Jack's exact properties each time he saved his mobile game.

There are some distinct advantages to this approach:

* No need to implement any kind of Change Data Capture in our underlying atemporal data systems
* No need to lookup the state of an entity at the time of a given event - it's already attached


Implications: our events are schemaed.

[kreps]: xxx
[dean]: http://manning.com/dean/

[snowplow-event-grammar]: /blog/2013/08/12/towards-universal-event-analytics-building-an-event-grammar
[keen-entities-vs-events]: https://keen.io/blog/53958349217/analytics-for-hackers-how-to-think-about-event-data
[iglu]: 

[hbase-versioning]: http://hbase.apache.org/book.html#versions
[datomic-rationale]: http://www.datomic.com/rationale.html
[log-trigger]: http://en.wikipedia.org/wiki/Log_trigger
[event-sourcing]: http://martinfowler.com/eaaDev/EventSourcing.html

[cdc]: http://en.wikipedia.org/wiki/Change_data_capture
